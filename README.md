
# Jetson Copilot Clean Build V1.0 ğŸš€

> **Private AI Assistant for NVIDIA Jetson â€” Fully Modernized, Ollama-powered, and RAG-ready**

---

## âœ¨ Overview

Jetson Copilot is a **local AI assistant** designed for NVIDIA Jetson devices. This modernized build fully replaces the original NVIDIA Copilot reference container with:

- âœ… Fully public Docker build (no NVIDIA private `nvcr.io` access required)
- âœ… Python 3.10 (fully compatible with latest LlamaIndex releases)
- âœ… Modular LlamaIndex hybrid RAG (Retrieval-Augmented Generation)
- âœ… Ollama 0.9.0 server running directly on Jetson host (ARM64 native)
- âœ… Simplified, reproducible, open-source friendly build process
- âœ… Compatible with JetPack 6.0 GA (L4T 36.4.0)

---

## ğŸ”¥ Key Differences from NVIDIA Reference Build

| Component | This Build | NVIDIA Original |
|------------|-------------|-------------------|
| Ollama version | 0.9.0 native host | Frozen older client |
| Ollama location | Runs directly on Jetson host | Bundled inside Docker |
| LlamaIndex version | 0.10.20 modular | 0.11.17 frozen |
| Python version | 3.10 | 3.8 |
| Docker base | Ubuntu 22.04 ARM64 (public) | NVIDIA private L4T |
| NVIDIA login required | âŒ No | âœ… Yes |
| Fully reproducible public build | âœ… Yes | âŒ No |
| Fully open-source safe | âœ… Yes | âŒ No |

---

## âš™ï¸ System Requirements

- Jetson device with JetPack 6.0 GA or newer (L4T 36.4.0+)
- NVIDIA container runtime (`nvidia-docker2`)
- Ollama 0.9.0 installed directly on Jetson host (ARM64-native)
- Docker installed

---

## ğŸš€ Install Instructions

### 1ï¸âƒ£ Install Ollama (directly on Jetson host)

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama version  # Verify version is 0.9.0 or newer
```

### 2ï¸âƒ£ Pull LLM models on host

```bash
ollama pull llama3
ollama pull llama4
ollama pull phi3
ollama pull mistral
ollama pull codellama
```

### 3ï¸âƒ£ Clone and build Jetson Copilot

```bash
git clone https://github.com/YOUR_REPO/jetson-copilot-clean.git
cd jetson-copilot-clean

chmod +x build_copilot.sh run_copilot.sh

./build_copilot.sh
./run_copilot.sh
```

---

## ğŸŒ Accessing Jetson Copilot

After launch, visit:

- `http://localhost:8501/` (on Jetson directly)
- `http://<JETSON_LAN_IP>:8501/` (from other machines on same network)

The `run_copilot.sh` script will automatically display your IP addresses.

---

## ğŸ§  How To Use Jetson Copilot

### Plain Chat (no RAG)

You can immediately chat with LLM models youâ€™ve downloaded via Ollama.

### RAG Mode (Use Documents & Knowledge)

Toggle **RAG mode** inside Streamlit sidebar to enable Retrieval-Augmented Generation using:

- Pre-built indexes (if available)
- Dynamically uploaded documents

You can build your own indexes directly within the app interface.

---

## ğŸ—‚ Directory Layout

```bash
jetson-copilot-clean/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ build_copilot.sh
â”œâ”€â”€ run_copilot.sh
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ images/
â””â”€â”€ indexes/  # Optional pre-built indexes
```

---

## ğŸ§ª Development Workflow

- Streamlit supports auto-reloading â€” simply edit `streamlit_app/app.py` while app is running.
- You can stop/restart container via `run_copilot.sh` easily.

---

## ğŸ³ Docker Build Notes

- Fully public Docker image using `arm64v8/ubuntu:22.04`
- Python 3.10 fully supported
- NVIDIA container runtime handles GPU passthrough (`--runtime=nvidia` used in launcher)

---

## ğŸ©º Troubleshooting

### Docker Permission Errors

Ensure your Jetson user is part of docker group:

```bash
sudo usermod -aG docker $USER
newgrp docker
```

If issues persist, logout and reboot.

### Model not found error

Be sure youâ€™ve pulled models directly via `ollama pull` on Jetson host before running app.

---

## ğŸ“œ License

Same as original NVIDIA Copilot: Apache 2.0

---

## â¤ï¸ Credits

- Forked and fully modernized from NVIDIA Jetson Copilot reference
- Heavy lifting by [human + AI](https://chat.openai.com)

---

ğŸš€ **Fully private, on-device, cloud-free AI Copilot for Jetson. Production-ready.**
